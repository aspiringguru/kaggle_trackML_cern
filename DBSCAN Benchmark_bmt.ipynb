{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall trackml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user git+https://github.com/LAL/trackml-library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import trackml\n",
    "\n",
    "#from trackml.dataset import load_event\n",
    "#from trackml.dataset import load_dataset\n",
    "#from trackml.score import score_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) \n",
      "[GCC 7.2.0]\n",
      "Version info.\n",
      "sys.version_info(major=3, minor=6, micro=4, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version\")\n",
    "print (sys.version)\n",
    "print(\"Version info.\")\n",
    "print (sys.version_info)\n",
    "#print (\"trackml.__version__:\", trackml.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trackml.dataset import load_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trackml.dataset import load_dataset\n",
    "from trackml.score import score_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"/home/ubuntu/kaggleData/\"\n",
    "path_to_train = dataDir+\"train_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This event is in Train_1\n",
    "event_prefix = \"event000001008\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/kaggleData/train_1/event000001008'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(path_to_train, event_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits, cells, particles, truth = load_event(os.path.join(path_to_train, event_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hit_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>volume_id</th>\n",
       "      <th>layer_id</th>\n",
       "      <th>module_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-82.837997</td>\n",
       "      <td>-11.24020</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-62.021400</td>\n",
       "      <td>-9.77127</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-69.657799</td>\n",
       "      <td>-6.66082</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-65.937302</td>\n",
       "      <td>-11.63420</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-78.020599</td>\n",
       "      <td>-9.37532</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hit_id          x         y       z  volume_id  layer_id  module_id\n",
       "0       1 -82.837997 -11.24020 -1502.5          7         2          1\n",
       "1       2 -62.021400  -9.77127 -1502.5          7         2          1\n",
       "2       3 -69.657799  -6.66082 -1502.5          7         2          1\n",
       "3       4 -65.937302 -11.63420 -1502.5          7         2          1\n",
       "4       5 -78.020599  -9.37532 -1502.5          7         2          1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "class Clusterer(object):\n",
    "    \n",
    "    def __init__(self, eps):\n",
    "        self.eps = eps\n",
    "        \n",
    "    \n",
    "    def _preprocess(self, hits):\n",
    "        \n",
    "        x = hits.x.values\n",
    "        y = hits.y.values\n",
    "        z = hits.z.values\n",
    "\n",
    "        r = np.sqrt(x**2 + y**2 + z**2)\n",
    "        hits['x2'] = x/r\n",
    "        hits['y2'] = y/r\n",
    "\n",
    "        r = np.sqrt(x**2 + y**2)\n",
    "        hits['z2'] = z/r\n",
    "\n",
    "        ss = StandardScaler()\n",
    "        X = ss.fit_transform(hits[['x2', 'y2', 'z2']].values)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def predict(self, hits):\n",
    "        \n",
    "        X = self._preprocess(hits)\n",
    "        \n",
    "        cl = DBSCAN(eps=self.eps, min_samples=1, algorithm='kd_tree')\n",
    "        labels = cl.fit_predict(X)\n",
    "        \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Clusterer(eps=0.008)\n",
    "labels = model.predict(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(model): <class '__main__.Clusterer'>\n",
      "type(labels): <class 'numpy.ndarray'> (111867,)\n"
     ]
    }
   ],
   "source": [
    "print (\"type(model):\", type(model))\n",
    "print (\"type(labels):\", type(labels), labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ... 60791 60789 60792]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_event_submission(event_id, hits, labels):\n",
    "    sub_data = np.column_stack(([event_id]*len(hits), hits.hit_id.values, labels))\n",
    "    submission = pd.DataFrame(data=sub_data, columns=[\"event_id\", \"hit_id\", \"track_id\"]).astype(int)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = create_one_event_submission(0, hits, labels)\n",
    "score = score_event(truth, submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score:  0.20589788785782545\n"
     ]
    }
   ],
   "source": [
    "print(\"Your score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object load_dataset at 0x7f8347b33258>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset(path_to_train, skip=1000, nevents=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for event 1000: 0.199\n",
      "Score for event 1001: 0.204\n",
      "Score for event 1002: 0.183\n",
      "Score for event 1003: 0.213\n",
      "Score for event 1004: 0.195\n",
      "Mean score: 0.199\n"
     ]
    }
   ],
   "source": [
    "dataset_submissions = []\n",
    "dataset_scores = []\n",
    "\n",
    "for event_id, hits, cells, particles, truth in load_dataset(path_to_train, skip=0, nevents=5):\n",
    "        \n",
    "    # Track pattern recognition\n",
    "    model = Clusterer(eps=0.008)\n",
    "    labels = model.predict(hits)\n",
    "        \n",
    "    # Prepare submission for an event\n",
    "    one_submission = create_one_event_submission(event_id, hits, labels)\n",
    "    dataset_submissions.append(one_submission)\n",
    "    \n",
    "    # Score for the event\n",
    "    score = score_event(truth, one_submission)\n",
    "    dataset_scores.append(score)\n",
    "    \n",
    "    print(\"Score for event %d: %.3f\" % (event_id, score))\n",
    "    \n",
    "print('Mean score: %.3f' % (np.mean(dataset_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  0\n",
      "Event ID:  1\n",
      "Event ID:  2\n",
      "Event ID:  3\n",
      "Event ID:  4\n",
      "Event ID:  5\n",
      "Event ID:  6\n",
      "Event ID:  7\n",
      "Event ID:  8\n",
      "Event ID:  9\n",
      "Event ID:  10\n",
      "Event ID:  11\n",
      "Event ID:  12\n",
      "Event ID:  13\n",
      "Event ID:  14\n",
      "Event ID:  15\n",
      "Event ID:  16\n",
      "Event ID:  17\n",
      "Event ID:  18\n",
      "Event ID:  19\n",
      "Event ID:  20\n",
      "Event ID:  21\n",
      "Event ID:  22\n",
      "Event ID:  23\n",
      "Event ID:  24\n",
      "Event ID:  25\n",
      "Event ID:  26\n",
      "Event ID:  27\n",
      "Event ID:  28\n",
      "Event ID:  29\n",
      "Event ID:  30\n",
      "Event ID:  31\n",
      "Event ID:  32\n",
      "Event ID:  33\n",
      "Event ID:  34\n",
      "Event ID:  35\n",
      "Event ID:  36\n",
      "Event ID:  37\n",
      "Event ID:  38\n",
      "Event ID:  39\n",
      "Event ID:  40\n",
      "Event ID:  41\n",
      "Event ID:  42\n",
      "Event ID:  43\n",
      "Event ID:  44\n",
      "Event ID:  45\n",
      "Event ID:  46\n",
      "Event ID:  47\n",
      "Event ID:  48\n",
      "Event ID:  49\n",
      "Event ID:  50\n",
      "Event ID:  51\n",
      "Event ID:  52\n",
      "Event ID:  53\n",
      "Event ID:  54\n",
      "Event ID:  55\n",
      "Event ID:  56\n",
      "Event ID:  57\n",
      "Event ID:  58\n",
      "Event ID:  59\n",
      "Event ID:  60\n",
      "Event ID:  61\n",
      "Event ID:  62\n",
      "Event ID:  63\n",
      "Event ID:  64\n",
      "Event ID:  65\n",
      "Event ID:  66\n",
      "Event ID:  67\n",
      "Event ID:  68\n",
      "Event ID:  69\n",
      "Event ID:  70\n",
      "Event ID:  71\n",
      "Event ID:  72\n",
      "Event ID:  73\n",
      "Event ID:  74\n",
      "Event ID:  75\n",
      "Event ID:  76\n",
      "Event ID:  77\n",
      "Event ID:  78\n",
      "Event ID:  79\n",
      "Event ID:  80\n",
      "Event ID:  81\n",
      "Event ID:  82\n",
      "Event ID:  83\n",
      "Event ID:  84\n",
      "Event ID:  85\n",
      "Event ID:  86\n",
      "Event ID:  87\n",
      "Event ID:  88\n",
      "Event ID:  89\n",
      "Event ID:  90\n",
      "Event ID:  91\n",
      "Event ID:  92\n",
      "Event ID:  93\n",
      "Event ID:  94\n",
      "Event ID:  95\n",
      "Event ID:  96\n",
      "Event ID:  97\n",
      "Event ID:  98\n",
      "Event ID:  99\n",
      "Event ID:  100\n",
      "Event ID:  101\n",
      "Event ID:  102\n",
      "Event ID:  103\n",
      "Event ID:  104\n",
      "Event ID:  105\n",
      "Event ID:  106\n",
      "Event ID:  107\n",
      "Event ID:  108\n",
      "Event ID:  109\n",
      "Event ID:  110\n",
      "Event ID:  111\n",
      "Event ID:  112\n",
      "Event ID:  113\n",
      "Event ID:  114\n",
      "Event ID:  115\n",
      "Event ID:  116\n",
      "Event ID:  117\n",
      "Event ID:  118\n",
      "Event ID:  119\n",
      "Event ID:  120\n",
      "Event ID:  121\n",
      "Event ID:  122\n",
      "Event ID:  123\n",
      "Event ID:  124\n",
      "creating submission file\n",
      "submit_file: submission.csv.gz\n"
     ]
    }
   ],
   "source": [
    "path_to_test = dataDir+\"test\"\n",
    "test_dataset_submissions = []\n",
    "submit_file = 'submission.csv.gz'\n",
    "\n",
    "create_submission = True # True for submission \n",
    "\n",
    "if create_submission:\n",
    "    for event_id, hits, cells in load_dataset(path_to_test, parts=['hits', 'cells']):\n",
    "\n",
    "        # Track pattern recognition\n",
    "        model = Clusterer(eps=0.008)\n",
    "        labels = model.predict(hits)\n",
    "\n",
    "        # Prepare submission for an event\n",
    "        one_submission = create_one_event_submission(event_id, hits, labels)\n",
    "        test_dataset_submissions.append(one_submission)\n",
    "        \n",
    "        print('Event ID: ', event_id)\n",
    "\n",
    "    # Create submission file\n",
    "    print(\"creating submission file\")\n",
    "    submission = pd.concat(test_dataset_submissions, axis=0)\n",
    "    submission.to_csv(submit_file, index=False, compression='gzip')\n",
    "    print (\"submit_file:\",submit_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/gitrepo/kaggle_trackML_cern'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB: unzip file prior to submission\n",
    "#note: kaggle submit tool would not work.\n",
    "#kaggle competitions submit -c trackml-particle-identification -f submission.csv -m \"1st submit\"\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
